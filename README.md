# GGSP-ALTEGRAD

## Demo

[Quick demo hosted at HF](https://huggingface.co/spaces/ymachta/GGSP-Project)

![Demo link above](assets/demo_ag.png "Optional title")

## Context
Challenge: [Generating Graphs from specified properties for the ALTEGRAD course](https://www.kaggle.com/competitions/generating-graphs-with-specified-properties/overview)


## Folder structure


```
.Repo
â”œâ”€â”€ NGG                    # Main module folder for the NGG project
â”‚   â”œâ”€â”€ main.py            # Entry point or table of contents for the project
â”‚   â”œâ”€â”€ train_utils        # Utilities and scripts for training models
â”‚   â”‚   â”œâ”€â”€ parser.py               # Script for parsing input arguments
â”‚   â”‚   â”œâ”€â”€ load_or_not_deepsets.py # Logic for loading or skipping DeepSets models
â”‚   â”‚   â”œâ”€â”€ load_or_not_stats_model.py # Logic for loading or skipping statistical models
â”‚   â”‚   â”œâ”€â”€ load_autoencoder.py    # Script for loading autoencoder models
â”‚   â”‚   â”œâ”€â”€ train_autoencoder.py   # Script for training autoencoder models
â”‚   â”‚   â”œâ”€â”€ train_denoiser.py      # Script for training denoiser models
â”‚   â”‚   â””â”€â”€ check_results.py       # Script for checking training results
â”‚   â”œâ”€â”€ utils              # Utility functions and scripts for general use
â”‚   â”‚   â”œâ”€â”€ extracts_feats.py      # Script for extracting features
â”‚   â”‚   â”œâ”€â”€ utils.py               # General utility functions
â”‚   â”‚   â”œâ”€â”€ verify_dataset_distribution.py # Script to verify dataset distribution
â”‚   â”‚   â””â”€â”€ verify_graph_features.py      # Script to verify graph features
â”‚   â”œâ”€â”€ autoencoders       # Folder containing autoencoder implementations
â”‚   â”‚   â”œâ”€â”€ autoencoder_base.py      # Base class for autoencoders
â”‚   â”‚   â”œâ”€â”€ autoencoder_concat.py    # Concatenation-based autoencoder
â”‚   â”‚   â”œâ”€â”€ autoencoder_GMVAE.py     # Gaussian Mixture VAE implementation
â”‚   â”‚   â”œâ”€â”€ autoencoder_GMVAEv2.py   # Version 2 of Gaussian Mixture VAE
â”‚   â”‚   â”œâ”€â”€ components               # Sub-folder for components used in autoencoders
â”‚   â”‚   â”‚   â”œâ”€â”€ deepsets.py            # DeepSets component
â”‚   â”‚   â”‚   â”œâ”€â”€ encoders               # Sub-folder for encoder components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GIN_base.py          # Base GIN encoder
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ GIN_concat.py        # GIN encoder with concatenation
â”‚   â”‚   â”‚   â”œâ”€â”€ decoders               # Sub-folder for decoder components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ decoder_base.py      # Base decoder
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ decoder_norm.py      # Normalization-based decoder
â”‚   â”œâ”€â”€ Denoisers          # Folder for denoiser models
â”‚   â”‚   â””â”€â”€ denoise_model.py      # Denoiser model implementation
â”‚   â””â”€â”€ commands.txt       # File containing various command line commands for reference
â”œâ”€â”€ data                   # Folder to store datasets
â”œâ”€â”€ progression_archive    # Folder for archiving progression and old versions
â”œâ”€â”€ model_weights          # Folder to store model weights
â””â”€â”€ setup.py               # Setup script for installing dependencies and packages
```


## Data

10000 synthetic graphs:
- 8000 Trainset
- 1000 Validation set
- 1000 Test set

Place the train, val and test data from [The kaggle dataset](https://www.kaggle.com/competitions/generating-graphs-with-specified-properties/data) in the .data/ folder you'll add.


## Model architechture and training

ðŸš§ Work in Progress

Check the [report in the repository](Project_report.pdf)

## Installation, Usage and Commands

Start by setting up the environment by runnning:

``` bash
pip install -r requirements.txt
```

setup the module NGG by using 

``` bash
pip install -e .
```

to train the model, use NGG/main.py with this command 

``` bash
python NGG/main.py --n-layers-decoder 6 --n-layers-encoder 4 --n-layers-denoise 4 \
--epochs-denoise 200 --epochs-autoencoder 200 --AE concat (or GMVAE) \
--name $Name_of_experiment --timesteps 1000 --additional
```

- ```--penalization-hyperparameters 1 ``` #to add MSE losses for n_nodes, n_triagles and n_edges
- ```--normalize ``` #adds self loops to the adj matrices

## References

